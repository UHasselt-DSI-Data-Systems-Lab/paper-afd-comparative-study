{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "827d5a78-6827-4034-93fa-4a5fe4d2384a",
   "metadata": {},
   "source": [
    "# Challenging relations\n",
    "\n",
    "Investigate challenging relations with regard to LHS uniqueness and RHS skew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e48fe5-e298-4ca0-a2fb-cd2462f8b3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# for Jupyter notebooks: add the path of 'code' to allow importing module\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\"))\n",
    "from afd_measures import utils as afd_utils\n",
    "from synthetic_data import inferrence as syn_inferrence\n",
    "from synthetic_data import utils as syn_utils\n",
    "\n",
    "difficult_relations = [\n",
    "    \"dblp10k.csv\",  # R3\n",
    "    \"t_biocase_gathering_agent_r72738_c18.csv\",  # R6\n",
    "]\n",
    "R = {\n",
    "    3: difficult_relations[0],\n",
    "    6: difficult_relations[1],\n",
    "}\n",
    "\n",
    "data_path = \"../../data/rwd\"\n",
    "results_path = \"../../results\"\n",
    "    \n",
    "rwd_results = pd.DataFrame()\n",
    "for file in filter(\n",
    "    lambda f: f.startswith(\"rwd_results_\") and f.endswith(\".csv\"),\n",
    "    os.listdir(results_path),\n",
    "):\n",
    "    rwd_results = pd.concat(\n",
    "        [rwd_results, pd.read_csv(os.path.join(results_path, file))]\n",
    "    )\n",
    "rwd_minus = rwd_results[rwd_results[afd_utils.measure_order].notna().all(axis=\"columns\")].query(\"exact_fd == False\").copy()\n",
    "\n",
    "difficult_data = {}\n",
    "difficult_results = {}\n",
    "for difficult_relation in difficult_relations:\n",
    "    difficult_data[difficult_relation] = pd.read_csv(\n",
    "        os.path.join(data_path, difficult_relation)\n",
    "    )\n",
    "    difficult_data[difficult_relation].columns = [\n",
    "        afd_utils.clean_colname(c) for c in difficult_data[difficult_relation].columns\n",
    "    ]\n",
    "    df = rwd_minus.query(\"table == @difficult_relation\")\n",
    "    difficult_results[difficult_relation] = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18d721c-abbc-4094-8ae9-87c79f65fa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add LHS uniqueness and RHS skew to the results\n",
    "for table, df in difficult_results.items():\n",
    "    difficult_results[table][\n",
    "        [\n",
    "            \"tuples\",\n",
    "            \"lhs_cardinality\",\n",
    "            \"rhs_cardinality\",\n",
    "            \"lhs_dist_alpha\",\n",
    "            \"lhs_dist_beta\",\n",
    "            \"rhs_dist_alpha\",\n",
    "            \"rhs_dist_beta\",\n",
    "            \"noise\",\n",
    "        ]\n",
    "    ] = df.apply(\n",
    "        lambda row: syn_inferrence.infer_settings(\n",
    "            difficult_data[table].loc[:, [row[\"lhs\"], row[\"rhs\"]]],\n",
    "            noise=False,\n",
    "        ),\n",
    "        axis=\"columns\",\n",
    "        result_type=\"expand\",\n",
    "    )\n",
    "    \n",
    "    difficult_results[table][\"lhs_uniqueness\"] = df[\"lhs_cardinality\"] / df[\"tuples\"]\n",
    "    difficult_results[table][\"rhs_skewness\"] = df.apply(\n",
    "        lambda row: syn_utils.beta_skewness(\n",
    "            row[\"rhs_dist_alpha\"], row[\"rhs_dist_beta\"]\n",
    "        ),\n",
    "        axis=\"columns\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12a5af4-376f-4d6d-9e97-6d53b780060c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mislabelled = []\n",
    "for table, df in difficult_results.items():\n",
    "    for measure in afd_utils.measure_order:\n",
    "        sorted_df = (\n",
    "            difficult_results[table]\n",
    "            .sort_values([measure, \"afd\"], ascending=[False, True])\n",
    "            .reset_index()\n",
    "            .copy()\n",
    "        )\n",
    "        max_afd = sorted_df[sorted_df.afd].index.max()\n",
    "        mislabelled_candidates = sorted_df.iloc[: max_afd + 1, :].query(\"afd == False\").copy()\n",
    "        mislabelled_byMeasure = {\n",
    "            \"table\": table,\n",
    "            \"measure\": measure,\n",
    "            \"max_afd_rank\": max_afd + 1,\n",
    "        }\n",
    "        for prop in (\"lhs_uniqueness\", \"rhs_skewness\"):\n",
    "            mislabelled_desc = mislabelled_candidates[prop].describe()\n",
    "            for column in mislabelled_desc.index:\n",
    "                mislabelled_byMeasure[f\"{prop}_{column}\"] = mislabelled_desc[column]\n",
    "        mislabelled.append(mislabelled_byMeasure)\n",
    "\n",
    "mislabelled = pd.DataFrame(mislabelled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc0caf4-4906-4518-bd20-06c49bed7c9a",
   "metadata": {},
   "source": [
    "## Figure 2 (c), upper part - means of mislabelled candidates in R3 and R6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6e4f13-8df9-45e6-9090-4d3c67453d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_map = {\n",
    "    v: f\"R{k}\" for k, v in R.items()\n",
    "}\n",
    "\n",
    "measures = afd_utils.measure_order\n",
    "measures.remove(\"reliable_fraction_of_information_norm\")\n",
    "measures.remove(\"mu_plus\")\n",
    "pd.pivot_table(\n",
    "    mislabelled,\n",
    "    index=\"measure\",\n",
    "    columns=\"table\",\n",
    "    values=[\"lhs_uniqueness_mean\", \"rhs_skewness_mean\"],\n",
    "    sort=False,\n",
    ").loc[afd_utils.measure_order, :].rename(columns=table_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e8ba66-c634-4353-89c7-22c4a9040dc2",
   "metadata": {},
   "source": [
    "## Figure 2 (c), lower part - means AFDs and non-AFDs in RWD$^-$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f621833e-12fb-41bc-bf01-e4f9bcf46cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rwd_data = {}\n",
    "for file in filter(lambda f: f.endswith(\".csv\"), os.listdir(os.path.join(data_path))):\n",
    "    rwd_data[file] = pd.read_csv(os.path.join(data_path, file))\n",
    "    rwd_data[file].columns = [\n",
    "        afd_utils.clean_colname(c) for c in rwd_data[file].columns\n",
    "    ]\n",
    "\n",
    "comparison = []\n",
    "for name, df in (\n",
    "    (\"AFD(R)\", rwd_minus.query(\"afd == True\").copy()),\n",
    "    (\"rest\", rwd_minus.query(\"afd == False\").copy())\n",
    "):\n",
    "    df[\n",
    "        [\n",
    "            \"tuples\",\n",
    "            \"lhs_cardinality\",\n",
    "            \"rhs_cardinality\",\n",
    "            \"lhs_dist_alpha\",\n",
    "            \"lhs_dist_beta\",\n",
    "            \"rhs_dist_alpha\",\n",
    "            \"rhs_dist_beta\",\n",
    "            \"noise\",\n",
    "        ]\n",
    "    ] = df.apply(\n",
    "        lambda row: syn_inferrence.infer_settings(\n",
    "            rwd_data[row[\"table\"]].loc[:, [row[\"lhs\"], row[\"rhs\"]]],\n",
    "            noise=False,\n",
    "        ),\n",
    "        axis=\"columns\",\n",
    "        result_type=\"expand\",\n",
    "    )\n",
    "    \n",
    "    df[\"lhs_uniqueness\"] = df[\"lhs_cardinality\"] / df[\"tuples\"]\n",
    "    df[\"rhs_skewness\"] = df.apply(\n",
    "        lambda row: syn_utils.beta_skewness(\n",
    "            row[\"rhs_dist_alpha\"], row[\"rhs_dist_beta\"]\n",
    "        ),\n",
    "        axis=\"columns\",\n",
    "    )\n",
    "    comparison.append({\n",
    "        \"name\": name,\n",
    "        \"lhs_uniqueness_mean\": df[\"lhs_uniqueness\"].mean(),\n",
    "        \"rhs_skewness_mean\": df[\"rhs_skewness\"].mean(),\n",
    "    })\n",
    "\n",
    "pd.DataFrame(comparison).set_index(\"name\", drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7043bb4f-62ed-4402-8289-97b28c01d66d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
