{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19580bd7-7191-4233-a99b-5b39140af600",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sensitivity Analysis\n",
    "\n",
    "Generate the plots showing the seperation on the synthetic datasets $Err$, $Uniq$ and $Skew$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2179a4d-bcaf-4206-822d-1f50c90ec184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict, Tuple\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for Jupyter notebooks: add the path of 'code' to allow importing module\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\"))\n",
    "from afd_measures import utils as afd_utils\n",
    "from synthetic_data import utils as syn_utils\n",
    "\n",
    "results_path = \"../../results\"\n",
    "\n",
    "def make_SYN_data(\n",
    "    df: pd.DataFrame,\n",
    "    x: str,\n",
    "    bins: int = 21,\n",
    "    min_val: float = 0.0,\n",
    "    max_val: float = 1.0,\n",
    ") -> Dict[Tuple[str, bool], pd.DataFrame]:\n",
    "    \"\"\"This method will bin results and calculate the means for analysis.\"\"\"\n",
    "    _df = df.copy()\n",
    "    _bins = np.linspace(min_val, max_val, num=bins)\n",
    "    _df[\"group\"] = pd.cut(_df[x], bins=_bins, include_lowest=True, labels=_bins[:-1])\n",
    "    dataset_dfs = {}\n",
    "    for measure in afd_utils.measure_order:\n",
    "        _local_df = pd.DataFrame(index=_bins)\n",
    "        for fd in (True, False):\n",
    "            _local_df.loc[:, \"fd\" if fd else \"random\"] = (\n",
    "                _df.query(\"fd == @fd\").groupby(\"group\")[measure].mean()\n",
    "            )\n",
    "        dataset_dfs[measure] = _local_df.dropna().copy()\n",
    "    return dataset_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919191db-c1a0-4fae-8d87-b9e2c8e11610",
   "metadata": {},
   "source": [
    "## Figure 3 - measure values on SYN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3e2d17-e86e-4186-b49f-e51260392d98",
   "metadata": {},
   "source": [
    "### $Err$ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4f91fe-83b6-42e6-9487-1d689a5f6a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(results_path, \"syn_e_results_0.csv\")):\n",
    "    raise ValueError(\"No SYN results found. Execute `generate_syn_e.ipynb` first.\")\n",
    "\n",
    "noisy_results = pd.DataFrame()\n",
    "for file in filter(\n",
    "    lambda f: f.startswith(\"syn_e_results_\") and f.endswith(\".csv\"),\n",
    "    os.listdir(results_path),\n",
    "):\n",
    "    noisy_results = pd.concat(\n",
    "        [noisy_results, pd.read_csv(os.path.join(results_path, file))]\n",
    "    )\n",
    "\n",
    "_df = noisy_results.query(\"n_type == 'copy'\").copy()\n",
    "noisy_bins = make_SYN_data(_df, \"noise\", bins=21, min_val=0.0, max_val=0.1)\n",
    "for measure, df in noisy_bins.items():\n",
    "    df[\"difference\"] = df[\"fd\"] - df[\"random\"]\n",
    "    df.to_csv(\n",
    "        f\"../../paper/syn_error_{measure}.dat\",\n",
    "        sep=\"\\t\",\n",
    "        index_label=\"error\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63a4423-2f91-483b-906f-56485a3b1ed6",
   "metadata": {},
   "source": [
    "### $Uniq$ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7081981-1bcd-4bd0-9806-8c29a686b351",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(results_path, \"syn_u_results_0.csv\")):\n",
    "    raise ValueError(\"No SYN results found. Execute `generate_syn_u.ipynb` first.\")\n",
    "\n",
    "keylike_results = pd.DataFrame()\n",
    "for file in filter(\n",
    "    lambda f: f.startswith(\"syn_u_results_\") and f.endswith(\".csv\"),\n",
    "    os.listdir(results_path),\n",
    "):\n",
    "    keylike_results = pd.concat(\n",
    "        [keylike_results, pd.read_csv(os.path.join(results_path, file))]\n",
    "    )\n",
    "\n",
    "keylike_results.loc[:, \"lhs_relative_uniqueness\"] = (\n",
    "    keylike_results.loc[:, \"lhs_cardinality_inferred\"]\n",
    "    / keylike_results.loc[:, \"tuples_inferred\"]\n",
    ")\n",
    "\n",
    "keylike_bins = make_SYN_data(\n",
    "    keylike_results, \"lhs_relative_uniqueness\", bins=11, min_val=0.0, max_val=1.0\n",
    ")\n",
    "for measure, df in keylike_bins.items():\n",
    "    df[\"difference\"] = df[\"fd\"] - df[\"random\"]\n",
    "    df.to_csv(\n",
    "        f\"../../paper/syn_keylike_{measure}.dat\",\n",
    "        sep=\"\\t\",\n",
    "        index_label=\"lhs_uniq\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0d5527-f797-40d0-a6a7-26686d0c61b3",
   "metadata": {},
   "source": [
    "### $Skew$ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1774c3-6ce1-4e8a-8b45-676e3a45cab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(results_path, \"syn_s_results_0.csv\")):\n",
    "    raise ValueError(\"No SYN results found. Execute `create_syn_s.ipynb` first.\")\n",
    "\n",
    "predominant_results = pd.DataFrame()\n",
    "for file in filter(\n",
    "    lambda f: f.startswith(\"syn_s_results_\") and f.endswith(\".csv\"),\n",
    "    os.listdir(results_path),\n",
    "):\n",
    "    predominant_results = pd.concat(\n",
    "        [predominant_results, pd.read_csv(os.path.join(results_path, file))]\n",
    "    )\n",
    "\n",
    "predominant_results.loc[:, \"rhs_skew\"] = predominant_results.loc[\n",
    "    :, [\"rhs_dist_alpha_inferred\", \"rhs_dist_beta_inferred\"]\n",
    "].apply(\n",
    "    lambda row: syn_utils.beta_skewness(\n",
    "        row[\"rhs_dist_alpha_inferred\"], row[\"rhs_dist_beta_inferred\"]\n",
    "    ),\n",
    "    axis=\"columns\",\n",
    ")\n",
    "\n",
    "skew_bins = make_SYN_data(\n",
    "    predominant_results, \"rhs_skew\", bins=11, min_val=0.0, max_val=10.0\n",
    ")\n",
    "for measure, df in skew_bins.items():\n",
    "    df[\"difference\"] = df[\"fd\"] - df[\"random\"]\n",
    "    df.to_csv(\n",
    "        f\"../../paper/syn_skew_{measure}.dat\",\n",
    "        sep=\"\\t\",\n",
    "        index_label=\"rhs_skew\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012ade0c-1efd-4e72-af94-8b9d3465119f",
   "metadata": {},
   "source": [
    "## Interactive plots\n",
    "\n",
    "Using `plotly`, we plot the same data as interactive plots, making it possible to inspect them in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055967ed-eca1-479a-b1a8-b1c07b11f4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.colors as plotly_colors\n",
    "\n",
    "colors = [\n",
    "    ( 55,126,184),\n",
    "    ( 77,175, 74),\n",
    "    (152, 78,163),\n",
    "    (255,127,  0),\n",
    "    (166, 86, 40),\n",
    "]\n",
    "\n",
    "measure_classes = {\n",
    "    \"Violation\": ['rho', 'g2', 'g3', 'g3_prime'],\n",
    "    \"Shannon\": ['shannon_g1_plus', 'fraction_of_information', 'reliable_fraction_of_information_plus', 'reliable_fraction_of_information_norm', 'smoothed_fraction_of_information'],\n",
    "    \"Logical\": ['g1_prime', 'pdep', 'tau', 'mu_plus'],\n",
    "}\n",
    "\n",
    "measure_map = {\n",
    "    \"mu_plus\": \"$\\mu^+$\",\n",
    "    \"g3_prime\": \"$g'_3$\",\n",
    "    \"g3\": r\"$g_3$\",\n",
    "    \"pdep\": r\"$\\text{pdep}$\",\n",
    "    \"tau\": r\"$\\tau$\",\n",
    "    \"rho\": r\"$\\rho$\",\n",
    "    \"g2\": r\"$g_2$\",\n",
    "    \"fraction_of_information\": r\"$\\text{FI}$\",\n",
    "    \"reliable_fraction_of_information_norm\": r\"$\\text{RFI}^{'+}$\",\n",
    "    \"g1_prime\": r\"$g_1, g'_1$\",\n",
    "    \"g1\": r\"$g_1$\",\n",
    "    \"reliable_fraction_of_information_plus\": r\"$\\text{RFI}^+$\",\n",
    "    \"smoothed_fraction_of_information\": r\"$\\text{SFI}$\",\n",
    "    \"shannon_g1_plus\": r\"$g_1^{S}$\",\n",
    "}\n",
    "\n",
    "\n",
    "def create_interactive_plots(data_tables: Dict[str, pd.DataFrame], x_axis_title: str, syn_name: str) -> List[go.Figure]:\n",
    "    \"\"\"\n",
    "    Create a plotly line-plots from per measure data tables created by `make_SYN_data`.\n",
    "    This method will create three plots, one for each measure class (set by `measure_classes`).\n",
    "    \"\"\"\n",
    "    figures = []\n",
    "    for measure_class, measures in measure_classes.items():\n",
    "        fig = go.Figure(\n",
    "            layout={\n",
    "                \"width\": 1000,\n",
    "                \"height\": 750,\n",
    "                \"xaxis\": {\"title\": x_axis_title},\n",
    "                \"yaxis\": {\"title\": \"measure values\", \"range\": [-0.05, 1.05]},\n",
    "                \"legend\": {\n",
    "                    \"orientation\": \"h\",\n",
    "                    \"yanchor\": \"top\",\n",
    "                    \"y\": 1.05,\n",
    "                    \"xanchor\": \"center\",\n",
    "                    \"x\": 0.5,\n",
    "                    \"entrywidth\": 50,\n",
    "                },\n",
    "                \"title\": f\"Differences of binned measure values of class {measure_class} for ${syn_name}$\",\n",
    "            },\n",
    "        )\n",
    "        for i, measure in enumerate(measures):\n",
    "            df = data_tables[measure]\n",
    "            for version in (\"fd\", \"random\"):\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=df.index,\n",
    "                        y=df.loc[:, version],\n",
    "                        mode=\"lines\",\n",
    "                        line={\n",
    "                            \"color\": f\"rgb{str(colors[i])}\",\n",
    "                            \"dash\": \"solid\" if version == \"fd\" else \"dash\",\n",
    "                        },\n",
    "                        name=measure_map[measure],\n",
    "                        showlegend=True if version == \"fd\" else False,\n",
    "                        legendgroup=measure,\n",
    "                    )\n",
    "                )\n",
    "        figures.append(fig)\n",
    "    return figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b99c2a-ab0c-44c1-8d0a-64f0148308a5",
   "metadata": {},
   "source": [
    "### $Err$ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cac1a8-661a-449e-959f-3cfdcc1e9d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fig in create_interactive_plots(noisy_bins, x_axis_title=\"Error rate\", syn_name=\"SYN^e\"):\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c3bbbd-1ca1-42fe-a68b-ad703072cd70",
   "metadata": {},
   "source": [
    "### $Uniq$ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70644f50-3cef-4c96-8929-be6366ca2a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fig in create_interactive_plots(keylike_bins, x_axis_title=\"LHS uniqueness\", syn_name=\"SYN^u\"):\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4797b951-4dd1-4a38-8085-f6ee2087d9b2",
   "metadata": {},
   "source": [
    "### $Skew$ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1b9a35-d195-410a-87dd-0dd93638d3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fig in create_interactive_plots(skew_bins, x_axis_title=\"RHS skew\", syn_name=\"SYN^s\"):\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1585ba4b-d811-4733-8d74-142544384b44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
