{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94cae0f8",
   "metadata": {},
   "source": [
    "# Create PR-AUC table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b53b1b",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "Load both, the datasets themselves as well as the results of the AFD measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cec0ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# for Jupyter notebooks: add the path of 'code' to allow importing module\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\"))\n",
    "from afd_measures import utils as afd_utils\n",
    "\n",
    "data_path = \"../../data\"\n",
    "gt_path = \"../../data/ground_truth.csv\"\n",
    "results_path = \"../../results\"\n",
    "\n",
    "rwd_data = {}\n",
    "for file in filter(lambda f: f.endswith(\".csv\"), os.listdir(os.path.join(data_path, \"rwd\"))):\n",
    "    rwd_data[file] = pd.read_csv(os.path.join(data_path, \"rwd\", file))\n",
    "    rwd_data[file].columns = [\n",
    "        afd_utils.clean_colname(c) for c in rwd_data[file].columns\n",
    "    ]\n",
    "\n",
    "rwd_results = pd.DataFrame()\n",
    "for file in filter(\n",
    "    lambda f: f.startswith(\"rwd_results_\") and f.endswith(\".csv\"),\n",
    "    os.listdir(results_path),\n",
    "):\n",
    "    rwd_results = pd.concat(\n",
    "        [rwd_results, pd.read_csv(os.path.join(results_path, file))]\n",
    "    )\n",
    "\n",
    "rwd_polluted_data = {}\n",
    "for file in filter(lambda f: f.endswith(\".csv\"), os.listdir(os.path.join(data_path, \"rwd_e\"))):\n",
    "    rwd_polluted_data[file] = pd.read_csv(os.path.join(data_path, \"rwd_e\", file))\n",
    "    rwd_polluted_data[file].columns = [\n",
    "        afd_utils.clean_colname(c) for c in rwd_polluted_data[file].columns\n",
    "    ]\n",
    "\n",
    "rwd_polluted_results = pd.DataFrame()\n",
    "for file in filter(\n",
    "    lambda f: f.startswith(\"rwd_e_results_\") and f.endswith(\".csv\"),\n",
    "    os.listdir(results_path),\n",
    "):\n",
    "    rwd_polluted_results = pd.concat(\n",
    "        [rwd_polluted_results, pd.read_csv(os.path.join(results_path, file))]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e50468",
   "metadata": {},
   "source": [
    "## Generate AUC table\n",
    "\n",
    "Generate the AUC table for both RWD and RWD$^e$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe42ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, precision_recall_curve\n",
    "\n",
    "from afd_measures import utils as afd_utils\n",
    "\n",
    "_data = {}\n",
    "subsets = {\n",
    "    \"RWD\": rwd_results.query(\"exact_fd == False\"),\n",
    "}\n",
    "for noise_type in (\"copy\", \"bogus\", \"typo\"):\n",
    "    for noise_level in (0.01, 0.02, 0.05, 0.1):\n",
    "        _df = rwd_polluted_results.query(\n",
    "            \"(exact_fd == False) & (noise_level == @noise_level) & (noise_type == @noise_type)\"\n",
    "        ).copy()\n",
    "        # add the polluted FDs to the ground truth\n",
    "        _df['afd'] = _df['afd'] | _df['fd_polluted']\n",
    "        subsets[\n",
    "            (f\"{noise_type} ${int(noise_level*100)}$\")\n",
    "        ] = _df\n",
    "\n",
    "for subset_name, subset_df in subsets.items():\n",
    "    _data[subset_name] = {}\n",
    "    for measure in afd_utils.measure_order:\n",
    "        _df = subset_df[subset_df[measure].notna()].copy()\n",
    "        precision, recall, _ = precision_recall_curve(\n",
    "            _df.loc[:, \"afd\"], _df.loc[:, measure]\n",
    "        )\n",
    "        _auc = auc(recall, precision)\n",
    "        _data[subset_name][afd_utils.measure_map[measure]] = round(_auc, 3)\n",
    "\n",
    "df = pd.DataFrame(_data)\n",
    "str_df = pd.DataFrame(index=df.index)\n",
    "for c in df.columns:\n",
    "    str_df[c] = df[c].astype(str)\n",
    "    _first, _second = df[c].sort_values(ascending=False).index[0:2]\n",
    "    for _both in (_first, _second):\n",
    "        str_df.loc[_both, c] = f\"\\\\textbf{{{str_df.loc[_both, c]}}}\"\n",
    "    str_df.loc[_first, c] = f\"\\\\underline{{{str_df.loc[_first, c]}}}\"\n",
    "\n",
    "str_df.to_csv(\"../../paper/table3_auc_overview.csv\", index_label=\"measure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a13afb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
