{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19580bd7-7191-4233-a99b-5b39140af600",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sensitivity Analysis\n",
    "\n",
    "Generate the plots showing the seperation on the synthetic datasets $Err$, $Uniq$ and $Skew$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2179a4d-bcaf-4206-822d-1f50c90ec184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict, Tuple\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for Jupyter notebooks: add the path of 'code' to allow importing module\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\"))\n",
    "from afd_measures import utils as afd_utils\n",
    "from synthetic_data import utils as syn_utils\n",
    "\n",
    "results_path = \"../../results\"\n",
    "\n",
    "def make_SYN_data(\n",
    "    df: pd.DataFrame,\n",
    "    x: str,\n",
    "    bins: int = 21,\n",
    "    min_val: float = 0.0,\n",
    "    max_val: float = 1.0,\n",
    ") -> Dict[Tuple[str, bool], pd.DataFrame]:\n",
    "    \"\"\"This method will bin results and calculate the means for analysis.\"\"\"\n",
    "    _df = df.copy()\n",
    "    _bins = np.linspace(min_val, max_val, num=bins)\n",
    "    _df[\"group\"] = pd.cut(_df[x], bins=_bins, include_lowest=True, labels=_bins[:-1])\n",
    "    dataset_dfs = {}\n",
    "    for measure in afd_utils.measure_order:\n",
    "        _local_df = pd.DataFrame(index=_bins)\n",
    "        for fd in (True, False):\n",
    "            _local_df.loc[:, \"fd\" if fd else \"random\"] = (\n",
    "                _df.query(\"fd == @fd\").groupby(\"group\")[measure].mean()\n",
    "            )\n",
    "        dataset_dfs[measure] = _local_df.dropna().copy()\n",
    "    return dataset_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919191db-c1a0-4fae-8d87-b9e2c8e11610",
   "metadata": {},
   "source": [
    "## Figure 1 - seperation ability of SYN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3e2d17-e86e-4186-b49f-e51260392d98",
   "metadata": {},
   "source": [
    "### $Err$ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4f91fe-83b6-42e6-9487-1d689a5f6a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(results_path, \"syn_e_results_0.csv\")):\n",
    "    raise ValueError(\"No SYN results found. Execute `generate_syn_e.ipynb` first.\")\n",
    "\n",
    "noisy_results = pd.DataFrame()\n",
    "for file in filter(\n",
    "    lambda f: f.startswith(\"syn_e_results_\") and f.endswith(\".csv\"),\n",
    "    os.listdir(results_path),\n",
    "):\n",
    "    noisy_results = pd.concat(\n",
    "        [noisy_results, pd.read_csv(os.path.join(results_path, file))]\n",
    "    )\n",
    "\n",
    "_df = noisy_results.query(\"n_type == 'copy'\").copy()\n",
    "noisy_bins = make_SYN_data(_df, \"noise\", bins=21, min_val=0.0, max_val=0.1)\n",
    "for measure, df in noisy_bins.items():\n",
    "    df[\"difference\"] = df[\"fd\"] - df[\"random\"]\n",
    "    df.to_csv(\n",
    "        f\"../../paper/syn_error_{measure}.dat\",\n",
    "        sep=\"\\t\",\n",
    "        index_label=\"error\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63a4423-2f91-483b-906f-56485a3b1ed6",
   "metadata": {},
   "source": [
    "### $Uniq$ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7081981-1bcd-4bd0-9806-8c29a686b351",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(results_path, \"syn_u_results_0.csv\")):\n",
    "    raise ValueError(\"No SYN results found. Execute `generate_syn_u.ipynb` first.\")\n",
    "\n",
    "keylike_results = pd.DataFrame()\n",
    "for file in filter(\n",
    "    lambda f: f.startswith(\"syn_u_results_\") and f.endswith(\".csv\"),\n",
    "    os.listdir(results_path),\n",
    "):\n",
    "    keylike_results = pd.concat(\n",
    "        [keylike_results, pd.read_csv(os.path.join(results_path, file))]\n",
    "    )\n",
    "\n",
    "keylike_results.loc[:, \"lhs_relative_uniqueness\"] = (\n",
    "    keylike_results.loc[:, \"lhs_cardinality_inferred\"]\n",
    "    / keylike_results.loc[:, \"tuples_inferred\"]\n",
    ")\n",
    "\n",
    "keylike_bins = make_SYN_data(\n",
    "    keylike_results, \"lhs_relative_uniqueness\", bins=11, min_val=0.0, max_val=1.0\n",
    ")\n",
    "for measure, df in keylike_bins.items():\n",
    "    df[\"difference\"] = df[\"fd\"] - df[\"random\"]\n",
    "    df.to_csv(\n",
    "        f\"../../paper/syn_keylike_{measure}.dat\",\n",
    "        sep=\"\\t\",\n",
    "        index_label=\"lhs_uniq\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0d5527-f797-40d0-a6a7-26686d0c61b3",
   "metadata": {},
   "source": [
    "### $Skew$ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1774c3-6ce1-4e8a-8b45-676e3a45cab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(results_path, \"syn_s_results_0.csv\")):\n",
    "    raise ValueError(\"No SYN results found. Execute `create_syn_s.ipynb` first.\")\n",
    "\n",
    "predominant_results = pd.DataFrame()\n",
    "for file in filter(\n",
    "    lambda f: f.startswith(\"syn_s_results_\") and f.endswith(\".csv\"),\n",
    "    os.listdir(results_path),\n",
    "):\n",
    "    predominant_results = pd.concat(\n",
    "        [predominant_results, pd.read_csv(os.path.join(results_path, file))]\n",
    "    )\n",
    "\n",
    "predominant_results.loc[:, \"rhs_skew\"] = predominant_results.loc[\n",
    "    :, [\"rhs_dist_alpha_inferred\", \"rhs_dist_beta_inferred\"]\n",
    "].apply(\n",
    "    lambda row: syn_utils.beta_skewness(\n",
    "        row[\"rhs_dist_alpha_inferred\"], row[\"rhs_dist_beta_inferred\"]\n",
    "    ),\n",
    "    axis=\"columns\",\n",
    ")\n",
    "\n",
    "skew_bins = make_SYN_data(\n",
    "    predominant_results, \"rhs_skew\", bins=11, min_val=0.0, max_val=10.0\n",
    ")\n",
    "for measure, df in skew_bins.items():\n",
    "    df[\"difference\"] = df[\"fd\"] - df[\"random\"]\n",
    "    df.to_csv(\n",
    "        f\"../../paper/syn_skew_{measure}.dat\",\n",
    "        sep=\"\\t\",\n",
    "        index_label=\"rhs_skew\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665f6e8b-1668-4950-8e88-f38f4d6204cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
